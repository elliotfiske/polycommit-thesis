\chapter{Future Work}

\section{Potential Improvements}

\par There are several improvements we could make to the experiment to draw a more definite conclusion about the effect of habit-forming gamification on student performance.

\subsection{Experiment Scope}

\par For the purposes of this thesis, we took a "breadth-first" approach to gathering data. That is, we released the app to a variety of classes (most were advanced Computer Science courses, but each covered completely separate topics) and allowed any students to participate in the experiment. This allowed us to get feedback and data from a variety of different perspectives.

\par However, after refining the experience based on the feedback from the "breadth-first" approach, the next step would be to take a "depth-first" approach to the experiment. That is, we would deploy the app in a more focused manner. We would choose a particular class, such as a introductory Calculus class, and deploy the app to every available section. This would give us more consistent data to work with, as we could compare the performance of different sections of the same class.

\subsection{Control Group}
\par A further improvement to the experiment would be implementing a control group. There are two main ways we could accomplish this. 

\par One method would be to only offer the app to certain sections of a class, while still collecting the scores on quizzes, exams and homework from the non-using sections. This approach has the advantage of being easy to implement, but has the disadvantage of introducing confounding variables to the experiment. The population of students who choose one section over another is not randomly sampled; for instance, students with better studying habits might take a class in an earlier section, causing the average grade on quizzes and exams to be higher in certain sections.

\par Another method would be to only offer the app to a randomly selected sample of students in the class. This has the advantage of being more scientifically sound, as a random sample on a large population would rule out other factors that might affect student performance. However, it would complicate the onboarding process, as we would be unable to present the app to the entire class and allow anyone with a Cal Poly account to sign up. One method would be to have the app be part of a mandatory graded assignment, and send a link to each of the participating students that allows them to sign up. This would hopefully ensure that all the students that were selected to participate would actually engage with the app.

\subsection{Experiment Duration}

\par This experiment took place over the first 5 weeks of Spring Quarter 2017. To gain a more complete understanding of how students respond to the app and how habits are formed over time, it would be advantageous to run further experiments over longer periods of time. Data from different quarters could be compared, adjusting different factors in the experiment to determine how users best respond to gamification. 

\par In addition, several users requested that questions continue past week 5 so they could have a study tool for the final. Future experiments could run for the duration of the whole quarter, allowing us to collect data from all the assignments throughout the quarter, including the final.

\subsection{User Feedback}

\subsubsection{Notifications}

\par As noted in \textbf{\hyperref[feedback-table]{Table \ref*{feedback-table}}}, users requested several additional features and improvements to the UI. One of the most requested features was the ability to receive notifications each day reminding the user to answer a question and thus earn Commitment. I had considered adding this to the app, but received some feedback during the dry run in Winter 2017 that email notifications would be annoying rather than useful. Thus, I chose to focus on other features rather than adding an element that might discourage certain students from using the app. For future experiments, an opt-in email notification system with a easy-to-use "Unsubscribe" option would likely increase user engagement while not annoying users that don't wish to be notified.

\subsubsection{Showing Answers}

\par A number of users requested in the final survey that answers, or answer hints, be shown after completing a question. Originally, the app did not have that feature, but I added it partway into the experiment because several users contacted me about it. The number of students that requested this feature, although it already existed, indicates that the UI does not make it clear that the feature is available. Currently, if students get a question wrong and exceed the maximum number of attempts, the app stays on the page with the closed challenge, and the answer is shown at the bottom of the screen. There could be some other indication that the answer is visible, perhaps on the course page itself.

\par Similarly, to address some user confusion I added an \textit{Explanation} field where I 